{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Life-Threatening Comment Detection and Filtering\n",
        "\n",
        "*author*:\n",
        "- Name: Saif-Ur-Rehman\n",
        "- Date: 2024-03-21\n",
        "- Tags: NLP, Sentiment Analysis, Text Classification, Python, Regular Expression\n",
        "---"
      ],
      "metadata": {
        "id": "u5wBSD3IPxYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description\n",
        "\n",
        "This project aims to develop a Python script for detecting and filtering life-threatening comments from a dataset of social media comments. The script utilizes Natural Language Processing (NLP) techniques, including sentiment analysis, to identify comments with negative sentiment and containing language indicative of life-threatening behavior.\n",
        "\n"
      ],
      "metadata": {
        "id": "0l7oIBrOQjdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "\n",
        "Social media platforms often face challenges in managing harmful content, including comments that contain threats of violence or harm to individuals. Automatic detection and filtering of such comments are essential for maintaining a safe online environment.\n",
        "\n",
        "In this project, we employ the following steps:\n",
        "\n",
        "1. **Data Preprocessing**: The comments are preprocessed to remove non-alphanumeric characters and converted to lowercase for uniformity.\n",
        "\n",
        "2. **Sentiment Analysis**: We use NLTK's SentimentIntensityAnalyzer to analyze the sentiment of each comment. Comments with negative sentiment are considered for further analysis.\n",
        "\n",
        "3. **Keyword Matching**: We identify comments containing keywords associated with life-threatening behavior, such as \"kill\", \"murder\", \"bomb\", etc.\n",
        "\n",
        "4. **Filtering**: Comments meeting both the negative sentiment and keyword matching criteria are filtered out as potential life-threatening comments.\n",
        "\n",
        "5. **Output**: The filtered comments are saved to a new CSV file for further analysis or moderation.\n",
        "\n",
        "## Tools Used\n",
        "\n",
        "- Python: Programming language used for script development.\n",
        "- NLTK: Natural Language Toolkit library for sentiment analysis.\n",
        "- Pandas: Library for data manipulation and handling CSV files.\n",
        "- Google Colab: Online platform for running Python scripts collaboratively."
      ],
      "metadata": {
        "id": "0ySYd7C9Q6Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset used in this project consists of social media comments scrapped from various platforms using Google API client. The comments include opinions, threats, and discussions that may contain life-threatening language.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Upload the 'ThreatsComments.csv' file containing social media comments to your Google Colab environment.\n",
        "2. Execute the provided Python script to detect and filter life-threatening comments.\n",
        "3. View the output CSV file 'FilteredLifeThreatCommentsUsingSentimentAnalysis.csv' containing the filtered comments.\n",
        "\n",
        "Feel free to customize and extend the script as needed for your specific use case or dataset."
      ],
      "metadata": {
        "id": "BFNyDsxKQ6Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Basic Filtering Life Threat Comments Using Simple Regular Expression Pattern**"
      ],
      "metadata": {
        "id": "Eb86_IYwIWSF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_0t87zP-7AE",
        "outputId": "ee8c72a7-780c-4311-ca3c-08c01f08d5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered life-threatening comments saved to FilteredLifeThreatComments.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e4008ceb996a>:15: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  filtered_comments_df = comments_df[comments_df['Comments'].str.contains(pattern, case=False, na=False)]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Read the CSV file using pandas\n",
        "input_file = 'ThreatsComments.csv'\n",
        "output_file = 'FilteredLifeThreatComments.csv'\n",
        "\n",
        "# Read the CSV file using pandas\n",
        "comments_df = pd.read_csv(input_file)\n",
        "\n",
        "# Regular expression pattern to match life-threatening language\n",
        "pattern = r'\\b(kill|murder|choke|strangle|bomb|shoot|stab|assault|attack|harm|destroy|exterminate|terminate|eliminate|slaughter|execute|smother|suffocate|blow up|explode|gun down|bludgeon|snuff out|strife|annihilate|obliterate|eradicate|crush)\\b'\n",
        "\n",
        "# Filter comments containing life-threatening language\n",
        "filtered_comments_df = comments_df[comments_df['Comments'].str.contains(pattern, case=False, na=False)]\n",
        "\n",
        "# Write filtered life-threatening comments to a new CSV file\n",
        "filtered_comments_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"Filtered life-threatening comments saved to\", output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Life-Threatening Comment Filtering using Sentiment Analysis**"
      ],
      "metadata": {
        "id": "IX0iaL0MI9uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Loading the sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(comment):\n",
        "    if not isinstance(comment, str):\n",
        "        comment = str(comment)\n",
        "    # Remove non-alphanumeric characters and convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', comment.lower())\n",
        "    return text\n",
        "\n",
        "# Function to filter out life-threatening comments\n",
        "def filter_life_threat_comments(comment):\n",
        "    # List of keywords indicating life-threatening language\n",
        "    life_threat_keywords = r'\\b(kill|murder|choke|strangle|bomb|shoot|stab|assault|attack|harm|destroy|exterminate|terminate|eliminate|slaughter|execute|smother|suffocate|blow up|explode|gun down|bludgeon|snuff out|strife|annihilate|obliterate|eradicate|crush)\\b'\n",
        "    for keyword in life_threat_keywords:\n",
        "        if keyword in comment:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Read the CSV file and filter out life-threatening comments\n",
        "input_file = 'ThreatsComments.csv'\n",
        "output_file = 'FilteredLifeThreatCommentsUsingSentimentAnalysis.csv'\n",
        "\n",
        "# Read the CSV file using pandas\n",
        "comments_df = pd.read_csv(input_file)\n",
        "\n",
        "filtered_comments = []\n",
        "\n",
        "for index, row in comments_df.iterrows():\n",
        "    comment = row['Comments']  # Corrected column name\n",
        "    # Preprocess the comment\n",
        "    comment = preprocess_text(comment)\n",
        "    # Perform sentiment analysis\n",
        "    sentiment_score = sia.polarity_scores(comment)['compound']\n",
        "    # Check if the sentiment is negative and the comment contains life-threatening language\n",
        "    if sentiment_score < 0 and filter_life_threat_comments(comment):\n",
        "        filtered_comments.append({'Id': row['ID'], 'Comments': comment})\n",
        "\n",
        "# Convert the filtered comments list to a DataFrame\n",
        "filtered_comments_df = pd.DataFrame(filtered_comments)\n",
        "\n",
        "# Write filtered life-threatening comments to a new CSV file\n",
        "filtered_comments_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"Filtered life-threatening comments saved to\", output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD6aXbOtDTe0",
        "outputId": "cba39abf-fe83-49f2-e239-474909e27e13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered life-threatening comments saved to FilteredLifeThreatComments1.csv\n"
          ]
        }
      ]
    }
  ]
}